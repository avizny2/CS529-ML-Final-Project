{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 Physical GPUs, 1 Logical GPUs\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "import numpy as np\n",
    "from keras.datasets import cifar10\n",
    "from keras.applications.resnet50 import ResNet50\n",
    "from keras.layers import GlobalAveragePooling2D, Dense\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Model\n",
    "from skimage.transform import resize\n",
    "\n",
    "import tensorflow as tf\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    # Restrict TensorFlow to only allocate 1GB * 2 of memory on the first GPU\n",
    "    try:\n",
    "        tf.config.experimental.set_virtual_device_configuration(\n",
    "            gpus[0],\n",
    "            [tf.config.experimental.VirtualDeviceConfiguration(memory_limit=1024 * 3)])\n",
    "        logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n",
    "        print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n",
    "    except RuntimeError as e:\n",
    "        # Virtual devices must be set before GPUs have been initialized\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_CLASSES = 10\n",
    "BATCH_SIZE = 100\n",
    "NUM_EPOCHS = 10\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import uuid\n",
    "arr_guid = [str(uuid.uuid4()) for i in range(BATCH_SIZE*NUM_CLASSES)] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing copy module \n",
    "import copy \n",
    "\n",
    "classes = []\n",
    "c_obj = {\n",
    "    'meta' : {},\n",
    "    'blocks': []\n",
    "}\n",
    "\n",
    "cifar_class_names = ['Airplane','Automobile','Bird','Cat','Deer','Dog','Frog','Horse','Ship','Truck']\n",
    "colors = [\"#1f77b4\",\"#ff7f0e\",\"#2ca02c\",\"#d62728\",\"#9467bd\",\"#8c564b\",\"#e377c2\",\"#7f7f7f\",\"#bcbd22\",\"#17becf\"]\n",
    "\n",
    "# using deepcopy for deepcopy \n",
    "for idx,i in enumerate(zip(cifar_class_names,colors)):\n",
    "    tmpX = copy.deepcopy(c_obj)\n",
    "    tmpX['meta']['name'] = str(i[0])\n",
    "    tmpX['meta']['color'] = str(i[1])\n",
    "    classes.append(tmpX)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'meta': {'name': 'Airplane', 'color': '#1f77b4'}, 'blocks': []},\n",
       " {'meta': {'name': 'Automobile', 'color': '#ff7f0e'}, 'blocks': []},\n",
       " {'meta': {'name': 'Bird', 'color': '#2ca02c'}, 'blocks': []},\n",
       " {'meta': {'name': 'Cat', 'color': '#d62728'}, 'blocks': []},\n",
       " {'meta': {'name': 'Deer', 'color': '#9467bd'}, 'blocks': []},\n",
       " {'meta': {'name': 'Dog', 'color': '#8c564b'}, 'blocks': []},\n",
       " {'meta': {'name': 'Frog', 'color': '#e377c2'}, 'blocks': []},\n",
       " {'meta': {'name': 'Horse', 'color': '#7f7f7f'}, 'blocks': []},\n",
       " {'meta': {'name': 'Ship', 'color': '#bcbd22'}, 'blocks': []},\n",
       " {'meta': {'name': 'Truck', 'color': '#17becf'}, 'blocks': []}]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LOAD CIFAR\n",
    "(x_train, y_train), (x_test, y_test) = cifar10.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A local file was found, but it seems to be incomplete or outdated because the auto file hash does not match the original value of 4d473c1dd8becc155b73f8504c6f6626 so we will re-download the data.\n",
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "94773248/94765736 [==============================] - 4s 0us/step\n",
      "Model: \"resnet50\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 32, 32, 3)]  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1_pad (ZeroPadding2D)       (None, 38, 38, 3)    0           input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1_conv (Conv2D)             (None, 16, 16, 64)   9472        conv1_pad[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1_bn (BatchNormalization)   (None, 16, 16, 64)   256         conv1_conv[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv1_relu (Activation)         (None, 16, 16, 64)   0           conv1_bn[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "pool1_pad (ZeroPadding2D)       (None, 18, 18, 64)   0           conv1_relu[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "pool1_pool (MaxPooling2D)       (None, 8, 8, 64)     0           pool1_pad[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_1_conv (Conv2D)    (None, 8, 8, 64)     4160        pool1_pool[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_1_bn (BatchNormali (None, 8, 8, 64)     256         conv2_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_1_relu (Activation (None, 8, 8, 64)     0           conv2_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_2_conv (Conv2D)    (None, 8, 8, 64)     36928       conv2_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_2_bn (BatchNormali (None, 8, 8, 64)     256         conv2_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_2_relu (Activation (None, 8, 8, 64)     0           conv2_block1_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_0_conv (Conv2D)    (None, 8, 8, 256)    16640       pool1_pool[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_3_conv (Conv2D)    (None, 8, 8, 256)    16640       conv2_block1_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_0_bn (BatchNormali (None, 8, 8, 256)    1024        conv2_block1_0_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_3_bn (BatchNormali (None, 8, 8, 256)    1024        conv2_block1_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_add (Add)          (None, 8, 8, 256)    0           conv2_block1_0_bn[0][0]          \n",
      "                                                                 conv2_block1_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_out (Activation)   (None, 8, 8, 256)    0           conv2_block1_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_1_conv (Conv2D)    (None, 8, 8, 64)     16448       conv2_block1_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_1_bn (BatchNormali (None, 8, 8, 64)     256         conv2_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_1_relu (Activation (None, 8, 8, 64)     0           conv2_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_2_conv (Conv2D)    (None, 8, 8, 64)     36928       conv2_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_2_bn (BatchNormali (None, 8, 8, 64)     256         conv2_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_2_relu (Activation (None, 8, 8, 64)     0           conv2_block2_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_3_conv (Conv2D)    (None, 8, 8, 256)    16640       conv2_block2_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_3_bn (BatchNormali (None, 8, 8, 256)    1024        conv2_block2_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_add (Add)          (None, 8, 8, 256)    0           conv2_block1_out[0][0]           \n",
      "                                                                 conv2_block2_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_out (Activation)   (None, 8, 8, 256)    0           conv2_block2_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_1_conv (Conv2D)    (None, 8, 8, 64)     16448       conv2_block2_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_1_bn (BatchNormali (None, 8, 8, 64)     256         conv2_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_1_relu (Activation (None, 8, 8, 64)     0           conv2_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_2_conv (Conv2D)    (None, 8, 8, 64)     36928       conv2_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_2_bn (BatchNormali (None, 8, 8, 64)     256         conv2_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_2_relu (Activation (None, 8, 8, 64)     0           conv2_block3_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_3_conv (Conv2D)    (None, 8, 8, 256)    16640       conv2_block3_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_3_bn (BatchNormali (None, 8, 8, 256)    1024        conv2_block3_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_add (Add)          (None, 8, 8, 256)    0           conv2_block2_out[0][0]           \n",
      "                                                                 conv2_block3_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_out (Activation)   (None, 8, 8, 256)    0           conv2_block3_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_1_conv (Conv2D)    (None, 4, 4, 128)    32896       conv2_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_1_bn (BatchNormali (None, 4, 4, 128)    512         conv3_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_1_relu (Activation (None, 4, 4, 128)    0           conv3_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_2_conv (Conv2D)    (None, 4, 4, 128)    147584      conv3_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_2_bn (BatchNormali (None, 4, 4, 128)    512         conv3_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_2_relu (Activation (None, 4, 4, 128)    0           conv3_block1_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_0_conv (Conv2D)    (None, 4, 4, 512)    131584      conv2_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_3_conv (Conv2D)    (None, 4, 4, 512)    66048       conv3_block1_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_0_bn (BatchNormali (None, 4, 4, 512)    2048        conv3_block1_0_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_3_bn (BatchNormali (None, 4, 4, 512)    2048        conv3_block1_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_add (Add)          (None, 4, 4, 512)    0           conv3_block1_0_bn[0][0]          \n",
      "                                                                 conv3_block1_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_out (Activation)   (None, 4, 4, 512)    0           conv3_block1_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_1_conv (Conv2D)    (None, 4, 4, 128)    65664       conv3_block1_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_1_bn (BatchNormali (None, 4, 4, 128)    512         conv3_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_1_relu (Activation (None, 4, 4, 128)    0           conv3_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_2_conv (Conv2D)    (None, 4, 4, 128)    147584      conv3_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_2_bn (BatchNormali (None, 4, 4, 128)    512         conv3_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_2_relu (Activation (None, 4, 4, 128)    0           conv3_block2_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_3_conv (Conv2D)    (None, 4, 4, 512)    66048       conv3_block2_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_3_bn (BatchNormali (None, 4, 4, 512)    2048        conv3_block2_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_add (Add)          (None, 4, 4, 512)    0           conv3_block1_out[0][0]           \n",
      "                                                                 conv3_block2_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_out (Activation)   (None, 4, 4, 512)    0           conv3_block2_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_1_conv (Conv2D)    (None, 4, 4, 128)    65664       conv3_block2_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_1_bn (BatchNormali (None, 4, 4, 128)    512         conv3_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_1_relu (Activation (None, 4, 4, 128)    0           conv3_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_2_conv (Conv2D)    (None, 4, 4, 128)    147584      conv3_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_2_bn (BatchNormali (None, 4, 4, 128)    512         conv3_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_2_relu (Activation (None, 4, 4, 128)    0           conv3_block3_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_3_conv (Conv2D)    (None, 4, 4, 512)    66048       conv3_block3_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_3_bn (BatchNormali (None, 4, 4, 512)    2048        conv3_block3_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_add (Add)          (None, 4, 4, 512)    0           conv3_block2_out[0][0]           \n",
      "                                                                 conv3_block3_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_out (Activation)   (None, 4, 4, 512)    0           conv3_block3_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_1_conv (Conv2D)    (None, 4, 4, 128)    65664       conv3_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_1_bn (BatchNormali (None, 4, 4, 128)    512         conv3_block4_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_1_relu (Activation (None, 4, 4, 128)    0           conv3_block4_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_2_conv (Conv2D)    (None, 4, 4, 128)    147584      conv3_block4_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_2_bn (BatchNormali (None, 4, 4, 128)    512         conv3_block4_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_2_relu (Activation (None, 4, 4, 128)    0           conv3_block4_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_3_conv (Conv2D)    (None, 4, 4, 512)    66048       conv3_block4_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_3_bn (BatchNormali (None, 4, 4, 512)    2048        conv3_block4_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_add (Add)          (None, 4, 4, 512)    0           conv3_block3_out[0][0]           \n",
      "                                                                 conv3_block4_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_out (Activation)   (None, 4, 4, 512)    0           conv3_block4_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_1_conv (Conv2D)    (None, 2, 2, 256)    131328      conv3_block4_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_1_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_1_relu (Activation (None, 2, 2, 256)    0           conv4_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_2_conv (Conv2D)    (None, 2, 2, 256)    590080      conv4_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_2_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_2_relu (Activation (None, 2, 2, 256)    0           conv4_block1_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_0_conv (Conv2D)    (None, 2, 2, 1024)   525312      conv3_block4_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_3_conv (Conv2D)    (None, 2, 2, 1024)   263168      conv4_block1_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_0_bn (BatchNormali (None, 2, 2, 1024)   4096        conv4_block1_0_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_3_bn (BatchNormali (None, 2, 2, 1024)   4096        conv4_block1_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_add (Add)          (None, 2, 2, 1024)   0           conv4_block1_0_bn[0][0]          \n",
      "                                                                 conv4_block1_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_out (Activation)   (None, 2, 2, 1024)   0           conv4_block1_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_1_conv (Conv2D)    (None, 2, 2, 256)    262400      conv4_block1_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_1_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_1_relu (Activation (None, 2, 2, 256)    0           conv4_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_2_conv (Conv2D)    (None, 2, 2, 256)    590080      conv4_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_2_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_2_relu (Activation (None, 2, 2, 256)    0           conv4_block2_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_3_conv (Conv2D)    (None, 2, 2, 1024)   263168      conv4_block2_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_3_bn (BatchNormali (None, 2, 2, 1024)   4096        conv4_block2_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_add (Add)          (None, 2, 2, 1024)   0           conv4_block1_out[0][0]           \n",
      "                                                                 conv4_block2_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_out (Activation)   (None, 2, 2, 1024)   0           conv4_block2_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_1_conv (Conv2D)    (None, 2, 2, 256)    262400      conv4_block2_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_1_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_1_relu (Activation (None, 2, 2, 256)    0           conv4_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_2_conv (Conv2D)    (None, 2, 2, 256)    590080      conv4_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_2_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_2_relu (Activation (None, 2, 2, 256)    0           conv4_block3_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_3_conv (Conv2D)    (None, 2, 2, 1024)   263168      conv4_block3_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_3_bn (BatchNormali (None, 2, 2, 1024)   4096        conv4_block3_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_add (Add)          (None, 2, 2, 1024)   0           conv4_block2_out[0][0]           \n",
      "                                                                 conv4_block3_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_out (Activation)   (None, 2, 2, 1024)   0           conv4_block3_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_1_conv (Conv2D)    (None, 2, 2, 256)    262400      conv4_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_1_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block4_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_1_relu (Activation (None, 2, 2, 256)    0           conv4_block4_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_2_conv (Conv2D)    (None, 2, 2, 256)    590080      conv4_block4_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_2_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block4_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_2_relu (Activation (None, 2, 2, 256)    0           conv4_block4_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_3_conv (Conv2D)    (None, 2, 2, 1024)   263168      conv4_block4_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_3_bn (BatchNormali (None, 2, 2, 1024)   4096        conv4_block4_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_add (Add)          (None, 2, 2, 1024)   0           conv4_block3_out[0][0]           \n",
      "                                                                 conv4_block4_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_out (Activation)   (None, 2, 2, 1024)   0           conv4_block4_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_1_conv (Conv2D)    (None, 2, 2, 256)    262400      conv4_block4_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_1_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block5_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_1_relu (Activation (None, 2, 2, 256)    0           conv4_block5_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_2_conv (Conv2D)    (None, 2, 2, 256)    590080      conv4_block5_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_2_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block5_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_2_relu (Activation (None, 2, 2, 256)    0           conv4_block5_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_3_conv (Conv2D)    (None, 2, 2, 1024)   263168      conv4_block5_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_3_bn (BatchNormali (None, 2, 2, 1024)   4096        conv4_block5_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_add (Add)          (None, 2, 2, 1024)   0           conv4_block4_out[0][0]           \n",
      "                                                                 conv4_block5_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_out (Activation)   (None, 2, 2, 1024)   0           conv4_block5_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_1_conv (Conv2D)    (None, 2, 2, 256)    262400      conv4_block5_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_1_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block6_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_1_relu (Activation (None, 2, 2, 256)    0           conv4_block6_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_2_conv (Conv2D)    (None, 2, 2, 256)    590080      conv4_block6_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_2_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block6_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_2_relu (Activation (None, 2, 2, 256)    0           conv4_block6_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_3_conv (Conv2D)    (None, 2, 2, 1024)   263168      conv4_block6_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_3_bn (BatchNormali (None, 2, 2, 1024)   4096        conv4_block6_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_add (Add)          (None, 2, 2, 1024)   0           conv4_block5_out[0][0]           \n",
      "                                                                 conv4_block6_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_out (Activation)   (None, 2, 2, 1024)   0           conv4_block6_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_1_conv (Conv2D)    (None, 1, 1, 512)    524800      conv4_block6_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_1_bn (BatchNormali (None, 1, 1, 512)    2048        conv5_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_1_relu (Activation (None, 1, 1, 512)    0           conv5_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_2_conv (Conv2D)    (None, 1, 1, 512)    2359808     conv5_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_2_bn (BatchNormali (None, 1, 1, 512)    2048        conv5_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_2_relu (Activation (None, 1, 1, 512)    0           conv5_block1_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_0_conv (Conv2D)    (None, 1, 1, 2048)   2099200     conv4_block6_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_3_conv (Conv2D)    (None, 1, 1, 2048)   1050624     conv5_block1_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_0_bn (BatchNormali (None, 1, 1, 2048)   8192        conv5_block1_0_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_3_bn (BatchNormali (None, 1, 1, 2048)   8192        conv5_block1_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_add (Add)          (None, 1, 1, 2048)   0           conv5_block1_0_bn[0][0]          \n",
      "                                                                 conv5_block1_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_out (Activation)   (None, 1, 1, 2048)   0           conv5_block1_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_1_conv (Conv2D)    (None, 1, 1, 512)    1049088     conv5_block1_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_1_bn (BatchNormali (None, 1, 1, 512)    2048        conv5_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_1_relu (Activation (None, 1, 1, 512)    0           conv5_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_2_conv (Conv2D)    (None, 1, 1, 512)    2359808     conv5_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_2_bn (BatchNormali (None, 1, 1, 512)    2048        conv5_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_2_relu (Activation (None, 1, 1, 512)    0           conv5_block2_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_3_conv (Conv2D)    (None, 1, 1, 2048)   1050624     conv5_block2_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_3_bn (BatchNormali (None, 1, 1, 2048)   8192        conv5_block2_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_add (Add)          (None, 1, 1, 2048)   0           conv5_block1_out[0][0]           \n",
      "                                                                 conv5_block2_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_out (Activation)   (None, 1, 1, 2048)   0           conv5_block2_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_1_conv (Conv2D)    (None, 1, 1, 512)    1049088     conv5_block2_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_1_bn (BatchNormali (None, 1, 1, 512)    2048        conv5_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_1_relu (Activation (None, 1, 1, 512)    0           conv5_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_2_conv (Conv2D)    (None, 1, 1, 512)    2359808     conv5_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_2_bn (BatchNormali (None, 1, 1, 512)    2048        conv5_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_2_relu (Activation (None, 1, 1, 512)    0           conv5_block3_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_3_conv (Conv2D)    (None, 1, 1, 2048)   1050624     conv5_block3_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_3_bn (BatchNormali (None, 1, 1, 2048)   8192        conv5_block3_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_add (Add)          (None, 1, 1, 2048)   0           conv5_block2_out[0][0]           \n",
      "                                                                 conv5_block3_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_out (Activation)   (None, 1, 1, 2048)   0           conv5_block3_add[0][0]           \n",
      "==================================================================================================\n",
      "Total params: 23,587,712\n",
      "Trainable params: 23,534,592\n",
      "Non-trainable params: 53,120\n",
      "__________________________________________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Instantiate the model \n",
    "# https://keras.io/api/applications/resnet/#resnet-and-resnetv2\n",
    "# TODO : upscaling 32x32 \n",
    "#        When setting `include_top=True` and loading `imagenet` weights, `input_shape` should be (224, 224, 3).\n",
    "\n",
    "input_shape = (32, 32, 3)\n",
    "\n",
    "\n",
    "base_model = {}\n",
    "base_model = ResNet50(include_top=False, weights='imagenet', input_shape=input_shape)\n",
    "#base_model = ResNet50(include_top=False, weights='imagenet', input_shape=input_shape, pooling='avg')\n",
    "\n",
    "print(base_model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 conv2_block3_add\n",
      "1 conv3_block4_add\n",
      "2 conv4_block6_add\n",
      "3 conv5_block3_add\n"
     ]
    }
   ],
   "source": [
    "Block_layers = [37,79,141,173]\n",
    "for idx in range(len(Block_layers)):\n",
    "    print(idx, base_model.get_layer(index = Block_layers[idx]).name)\n",
    "    #print(idx, base_model.get_layer(index = idx).__class__.__name__)\n",
    "    \n",
    "    #['BatchNormalization','ZeroPadding2D','max_pooling2d_1']\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000, 32, 32, 3)\n",
      "(1000,)\n"
     ]
    }
   ],
   "source": [
    "# prepare the batches here (ideally we want BATCH_SIZE samples for all NUM_CLASSES classes)\n",
    "all_classes = np.unique(y_test)\n",
    "\n",
    "# total batch images:\n",
    "mini_batches = []\n",
    "\n",
    "mini_y = []\n",
    "\n",
    "for c_i in all_classes:\n",
    "    result = np.where(y_test == c_i)\n",
    "    batch = result[0][:BATCH_SIZE].astype(int)\n",
    "    \n",
    "    mini_y = np.concatenate((mini_y,batch))\n",
    "    \n",
    "    for idx in batch:\n",
    "        mini_batches.append(x_test[idx])\n",
    "        \n",
    "        \n",
    "mini_batches = np.stack(mini_batches)\n",
    "print(mini_batches.shape)\n",
    "\n",
    "mini_y = mini_y.astype(int)\n",
    "print(mini_y.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.0, 1.0)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mini_batches = mini_batches/255.0\n",
    "np.min(mini_batches),np.max(mini_batches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000, 3)\n",
      "(1000, 3)\n",
      "1 conv1_pad\n",
      "(1000, 3)\n",
      "(1000, 3)\n",
      "3 conv1_bn\n",
      "(1000, 3)\n",
      "(1000, 3)\n",
      "5 pool1_pad\n",
      "(1000, 3)\n",
      "(1000, 3)\n",
      "(1000, 3)\n",
      "(1000, 3)\n",
      "8 conv2_block1_1_bn\n",
      "(1000, 3)\n",
      "(1000, 3)\n",
      "(1000, 3)\n",
      "(1000, 3)\n",
      "11 conv2_block1_2_bn\n",
      "(1000, 3)\n",
      "(1000, 3)\n",
      "(1000, 3)\n",
      "(1000, 3)\n",
      "(1000, 3)\n",
      "(1000, 3)\n",
      "15 conv2_block1_0_bn\n",
      "16 conv2_block1_3_bn\n",
      "(1000, 3)\n",
      "(1000, 3)\n",
      "(1000, 3)\n",
      "(1000, 3)\n",
      "(1000, 3)\n",
      "(1000, 3)\n",
      "20 conv2_block2_1_bn\n",
      "(1000, 3)\n",
      "(1000, 3)\n",
      "(1000, 3)\n",
      "(1000, 3)\n",
      "23 conv2_block2_2_bn\n",
      "(1000, 3)\n",
      "(1000, 3)\n",
      "(1000, 3)\n",
      "(1000, 3)\n",
      "26 conv2_block2_3_bn\n",
      "(1000, 3)\n",
      "(1000, 3)\n",
      "(1000, 3)\n",
      "(1000, 3)\n",
      "(1000, 3)\n",
      "(1000, 3)\n",
      "30 conv2_block3_1_bn\n",
      "(1000, 3)\n",
      "(1000, 3)\n",
      "(1000, 3)\n",
      "(1000, 3)\n",
      "33 conv2_block3_2_bn\n",
      "(1000, 3)\n",
      "(1000, 3)\n",
      "(1000, 3)\n",
      "(1000, 3)\n",
      "36 conv2_block3_3_bn\n",
      "(1000, 3)\n",
      "(1000, 3)\n",
      "(1000, 3)\n",
      "(1000, 3)\n",
      "(1000, 3)\n",
      "(1000, 3)\n",
      "40 conv3_block1_1_bn\n",
      "(1000, 3)\n",
      "(1000, 3)\n",
      "(1000, 3)\n",
      "(1000, 3)\n",
      "43 conv3_block1_2_bn\n",
      "(1000, 3)\n",
      "(1000, 3)\n",
      "(1000, 3)\n",
      "(1000, 3)\n",
      "(1000, 3)\n",
      "(1000, 3)\n",
      "47 conv3_block1_0_bn\n",
      "48 conv3_block1_3_bn\n",
      "(1000, 3)\n",
      "(1000, 3)\n",
      "(1000, 3)\n",
      "(1000, 3)\n",
      "(1000, 3)\n",
      "(1000, 3)\n",
      "52 conv3_block2_1_bn\n",
      "(1000, 3)\n",
      "(1000, 3)\n",
      "(1000, 3)\n",
      "(1000, 3)\n",
      "55 conv3_block2_2_bn\n",
      "(1000, 3)\n",
      "(1000, 3)\n",
      "(1000, 3)\n",
      "(1000, 3)\n",
      "58 conv3_block2_3_bn\n",
      "(1000, 3)\n",
      "(1000, 3)\n",
      "(1000, 3)\n",
      "(1000, 3)\n",
      "(1000, 3)\n",
      "(1000, 3)\n",
      "62 conv3_block3_1_bn\n",
      "(1000, 3)\n",
      "(1000, 3)\n",
      "(1000, 3)\n",
      "(1000, 3)\n",
      "65 conv3_block3_2_bn\n",
      "(1000, 3)\n",
      "(1000, 3)\n",
      "(1000, 3)\n",
      "(1000, 3)\n",
      "68 conv3_block3_3_bn\n",
      "(1000, 3)\n",
      "(1000, 3)\n",
      "(1000, 3)\n",
      "(1000, 3)\n",
      "(1000, 3)\n",
      "(1000, 3)\n",
      "72 conv3_block4_1_bn\n",
      "(1000, 3)\n",
      "(1000, 3)\n",
      "(1000, 3)\n",
      "(1000, 3)\n",
      "75 conv3_block4_2_bn\n",
      "(1000, 3)\n",
      "(1000, 3)\n",
      "(1000, 3)\n",
      "(1000, 3)\n",
      "78 conv3_block4_3_bn\n",
      "(1000, 3)\n",
      "(1000, 3)\n",
      "(1000, 3)\n",
      "(1000, 3)\n",
      "(1000, 3)\n",
      "(1000, 3)\n",
      "82 conv4_block1_1_bn\n",
      "(1000, 3)\n",
      "(1000, 3)\n",
      "(1000, 3)\n",
      "(1000, 3)\n",
      "85 conv4_block1_2_bn\n",
      "(1000, 3)\n",
      "(1000, 3)\n",
      "(1000, 3)\n",
      "(1000, 3)\n",
      "(1000, 3)\n",
      "(1000, 3)\n",
      "89 conv4_block1_0_bn\n",
      "90 conv4_block1_3_bn\n",
      "(1000, 3)\n",
      "(1000, 3)\n",
      "(1000, 3)\n",
      "(1000, 3)\n",
      "(1000, 3)\n",
      "(1000, 3)\n",
      "94 conv4_block2_1_bn\n",
      "(1000, 3)\n",
      "(1000, 3)\n",
      "(1000, 3)\n",
      "(1000, 3)\n",
      "97 conv4_block2_2_bn\n",
      "(1000, 3)\n",
      "(1000, 3)\n",
      "(1000, 3)\n",
      "(1000, 3)\n",
      "100 conv4_block2_3_bn\n",
      "(1000, 3)\n",
      "(1000, 3)\n",
      "(1000, 3)\n",
      "(1000, 3)\n",
      "(1000, 3)\n",
      "(1000, 3)\n",
      "104 conv4_block3_1_bn\n",
      "(1000, 3)\n",
      "(1000, 3)\n",
      "(1000, 3)\n",
      "(1000, 3)\n",
      "107 conv4_block3_2_bn\n",
      "(1000, 3)\n",
      "(1000, 3)\n",
      "(1000, 3)\n",
      "(1000, 3)\n",
      "110 conv4_block3_3_bn\n",
      "(1000, 3)\n",
      "(1000, 3)\n",
      "(1000, 3)\n",
      "(1000, 3)\n",
      "(1000, 3)\n",
      "(1000, 3)\n",
      "114 conv4_block4_1_bn\n",
      "(1000, 3)\n",
      "(1000, 3)\n",
      "(1000, 3)\n",
      "(1000, 3)\n",
      "117 conv4_block4_2_bn\n",
      "(1000, 3)\n",
      "(1000, 3)\n",
      "(1000, 3)\n",
      "(1000, 3)\n",
      "120 conv4_block4_3_bn\n",
      "(1000, 3)\n",
      "(1000, 3)\n",
      "(1000, 3)\n",
      "(1000, 3)\n",
      "(1000, 3)\n",
      "(1000, 3)\n",
      "124 conv4_block5_1_bn\n",
      "(1000, 3)\n",
      "(1000, 3)\n",
      "(1000, 3)\n",
      "(1000, 3)\n",
      "127 conv4_block5_2_bn\n",
      "(1000, 3)\n",
      "(1000, 3)\n",
      "(1000, 3)\n",
      "(1000, 3)\n",
      "130 conv4_block5_3_bn\n",
      "(1000, 3)\n",
      "(1000, 3)\n",
      "(1000, 3)\n",
      "(1000, 3)\n",
      "(1000, 3)\n",
      "(1000, 3)\n",
      "134 conv4_block6_1_bn\n",
      "(1000, 3)\n",
      "(1000, 3)\n",
      "(1000, 3)\n",
      "(1000, 3)\n",
      "137 conv4_block6_2_bn\n",
      "(1000, 3)\n",
      "(1000, 3)\n",
      "(1000, 3)\n",
      "(1000, 3)\n",
      "140 conv4_block6_3_bn\n",
      "(1000, 3)\n",
      "(1000, 3)\n",
      "(1000, 3)\n",
      "(1000, 3)\n",
      "(1000, 3)\n",
      "(1000, 3)\n",
      "144 conv5_block1_1_bn\n",
      "(1000, 3)\n",
      "(1000, 3)\n",
      "(1000, 3)\n",
      "(1000, 3)\n",
      "147 conv5_block1_2_bn\n",
      "(1000, 3)\n",
      "(1000, 3)\n",
      "(1000, 3)\n",
      "(1000, 3)\n",
      "(1000, 3)\n",
      "(1000, 3)\n",
      "151 conv5_block1_0_bn\n",
      "152 conv5_block1_3_bn\n",
      "(1000, 3)\n",
      "(1000, 3)\n",
      "(1000, 3)\n",
      "(1000, 3)\n",
      "(1000, 3)\n",
      "(1000, 3)\n",
      "156 conv5_block2_1_bn\n",
      "(1000, 3)\n",
      "(1000, 3)\n",
      "(1000, 3)\n",
      "(1000, 3)\n",
      "159 conv5_block2_2_bn\n",
      "(1000, 3)\n",
      "(1000, 3)\n",
      "(1000, 3)\n",
      "(1000, 3)\n",
      "162 conv5_block2_3_bn\n",
      "(1000, 3)\n",
      "(1000, 3)\n",
      "(1000, 3)\n",
      "(1000, 3)\n",
      "(1000, 3)\n",
      "(1000, 3)\n",
      "166 conv5_block3_1_bn\n",
      "(1000, 3)\n",
      "(1000, 3)\n",
      "(1000, 3)\n",
      "(1000, 3)\n",
      "169 conv5_block3_2_bn\n",
      "(1000, 3)\n",
      "(1000, 3)\n",
      "(1000, 3)\n",
      "(1000, 3)\n",
      "172 conv5_block3_3_bn\n",
      "(1000, 3)\n",
      "(1000, 3)\n",
      "(1000, 3)\n",
      "(1000, 3)\n"
     ]
    }
   ],
   "source": [
    "# Import PCA from sklearn\n",
    "from sklearn.decomposition import PCA\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt \n",
    "\n",
    "tmp_layers_class_0 = []\n",
    "tmp_layers_class_1 = []\n",
    "tmp_layers_class_2 = []\n",
    "tmp_layers_class_3 = []\n",
    "tmp_layers_class_4 = []\n",
    "tmp_layers_class_5 = []\n",
    "tmp_layers_class_6 = []\n",
    "tmp_layers_class_7 = []\n",
    "tmp_layers_class_8 = []\n",
    "tmp_layers_class_9 = []\n",
    "\n",
    "for idx in range(len(base_model.layers)):\n",
    "    avoid_layers = ['BatchNormalization','ZeroPadding2D','max_pooling2d_1']\n",
    "    layer_name = base_model.get_layer(index = idx).name\n",
    "    layer_type = base_model.get_layer(index = idx).__class__.__name__\n",
    "    \n",
    "    if layer_type in avoid_layers:\n",
    "        print(idx, layer_name)\n",
    "        \n",
    "    if layer_type not in avoid_layers:\n",
    "        x = base_model.layers[idx].output\n",
    "        x = GlobalAveragePooling2D()(x)\n",
    "        model_cut = Model(inputs = base_model.input, outputs = x)\n",
    "\n",
    "        pred = model_cut.predict(mini_batches)\n",
    "\n",
    "\n",
    "        # Instantiate PCA\n",
    "        pca = PCA(n_components=3)\n",
    "        X = pca.fit_transform(pred)\n",
    "        \n",
    "        # INSTANTIATE TSNE\n",
    "        tsne = TSNE(n_components=3, perplexity=40, n_iter=300)\n",
    "        XTS = tsne.fit_transform(pred)\n",
    "\n",
    "\n",
    "        print(X.shape)\n",
    "        print(XTS.shape)\n",
    "        X = X[:,:2]  #just keep the two columns for visualization\n",
    "        XTS = XTS[:,:2]  #just keep the two columns for visualization\n",
    "        \"\"\"\n",
    "        # Create a new dataset from principal components \n",
    "        df = pd.DataFrame(data = X, columns = ['PC1', 'PC2'])\n",
    "\n",
    "        target = pd.Series(np.array(y_test[mini_y]).flatten(), name='y')\n",
    "\n",
    "        result_df = pd.concat([df, target], axis=1)\n",
    "\n",
    "\n",
    "        # Visualize Principal Components with a scatter plot\n",
    "        fig = plt.figure(figsize = (8,6))\n",
    "        ax = fig.add_subplot(1,1,1) \n",
    "        ax.set_xlabel('First Principal Component ', fontsize = 15)\n",
    "        ax.set_ylabel('Second Principal Component ', fontsize = 15)\n",
    "        ax.set_title('Principal Component Analysis (2PCs)', fontsize = 20)\n",
    "\n",
    "        targets = np.unique(y_test)\n",
    "        colors = [\"#1f77b4\",\"#ff7f0e\",\"#2ca02c\",\"#d62728\",\"#9467bd\",\"#8c564b\",\"#e377c2\",\"#7f7f7f\",\"#bcbd22\",\"#17becf\"]\n",
    "        for target, color in zip(targets, colors):\n",
    "            indicesToKeep = result_df.loc[result_df['y'] == target]\n",
    "            ax.scatter(indicesToKeep['PC1'], \n",
    "                       indicesToKeep['PC2'], \n",
    "                       c = color, \n",
    "                       s = 50)\n",
    "        ax.legend(targets)\n",
    "        ax.grid()\n",
    "        \"\"\"\n",
    "        \n",
    "        tmp_layers = []\n",
    "        for idx, i in enumerate(X):\n",
    "            if idx == 100:\n",
    "                l_obj = {\n",
    "                    \"name\" : layer_name,\n",
    "                    \"layers\" : tmp_layers\n",
    "                }\n",
    "                tmp_layers_class_0.append(l_obj)\n",
    "                \n",
    "                tmp_layers = []\n",
    "            elif idx == 200:\n",
    "                l_obj = {\n",
    "                    \"name\" : layer_name,\n",
    "                    \"layers\" : tmp_layers\n",
    "                }\n",
    "                tmp_layers_class_1.append(l_obj)\n",
    "                tmp_layers = []\n",
    "            elif idx == 300:\n",
    "                l_obj = {\n",
    "                    \"name\" : layer_name,\n",
    "                    \"layers\" : tmp_layers\n",
    "                }\n",
    "                tmp_layers_class_2.append(l_obj)\n",
    "                tmp_layers = []\n",
    "            elif idx == 400:\n",
    "                l_obj = {\n",
    "                    \"name\" : layer_name,\n",
    "                    \"layers\" : tmp_layers\n",
    "                }\n",
    "                tmp_layers_class_3.append(l_obj)\n",
    "                tmp_layers = []\n",
    "            elif idx == 500:\n",
    "                l_obj = {\n",
    "                    \"name\" : layer_name,\n",
    "                    \"layers\" : tmp_layers\n",
    "                }\n",
    "                tmp_layers_class_4.append(l_obj)\n",
    "                tmp_layers = []\n",
    "            elif idx == 600:\n",
    "                l_obj = {\n",
    "                    \"name\" : layer_name,\n",
    "                    \"layers\" : tmp_layers\n",
    "                }\n",
    "                tmp_layers_class_5.append(l_obj)\n",
    "                tmp_layers = []\n",
    "            elif idx == 700:\n",
    "                l_obj = {\n",
    "                    \"name\" : layer_name,\n",
    "                    \"layers\" : tmp_layers\n",
    "                }\n",
    "                tmp_layers_class_6.append(l_obj)\n",
    "                tmp_layers = []\n",
    "            elif idx == 800:\n",
    "                l_obj = {\n",
    "                    \"name\" : layer_name,\n",
    "                    \"layers\" : tmp_layers\n",
    "                }\n",
    "                tmp_layers_class_7.append(l_obj)\n",
    "                tmp_layers = []\n",
    "            elif idx == 900:\n",
    "                l_obj = {\n",
    "                    \"name\" : layer_name,\n",
    "                    \"layers\" : tmp_layers\n",
    "                }\n",
    "                tmp_layers_class_8.append(l_obj)\n",
    "                tmp_layers = []\n",
    "\n",
    "\n",
    "            point = {\n",
    "                'x_pca': str(i[0]),\n",
    "                'y_pca': str(i[1]),\n",
    "                'x_tsne': str(XTS[idx][0]),\n",
    "                'y_tsne': str(XTS[idx][1]),\n",
    "                'actv': [],\n",
    "                'pred': str(y_test[mini_y[idx]][0]),\n",
    "                'actual': str(y_test[mini_y[idx]][0]),\n",
    "                'guid': arr_guid[idx]\n",
    "            }            \n",
    "            tmp_layers.append(point)\n",
    "\n",
    "            if idx == 999:\n",
    "                l_obj = {\n",
    "                    \"name\" : layer_name,\n",
    "                    \"layers\" : tmp_layers\n",
    "                }\n",
    "                tmp_layers_class_9.append(l_obj)\n",
    "                tmp_layers = []\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-12-3513474db095>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     11\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mlayer_type\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mavoid_layers\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 13\u001b[1;33m         \u001b[1;32mif\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mBlock_layers\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     14\u001b[0m             \u001b[0mclasses\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'blocks'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()"
     ]
    }
   ],
   "source": [
    "\n",
    "sub_block0 = []\n",
    "sub_block1 = []\n",
    "sub_block2 = []\n",
    "sub_block3 = []\n",
    "\n",
    "for idx in range(len(base_model.layers)):\n",
    "    avoid_layers = ['BatchNormalization','ZeroPadding2D','max_pooling2d_1']\n",
    "    layer_name = base_model.get_layer(index = idx).name\n",
    "    layer_type = base_model.get_layer(index = idx).__class__.__name__\n",
    "    \n",
    "    if layer_type not in avoid_layers:\n",
    "        \n",
    "        if idx <= 37:\n",
    "            sub_block0.append"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "bl_obj_0 = {\n",
    "    \"meta\": {\n",
    "        \"name\": \"Conv Block 1\"\n",
    "    },\n",
    "    'layers': tmp_layers_class_0[0:(37+2-13)]\n",
    "}\n",
    "bl_obj_1 = {\n",
    "    \"meta\": {\n",
    "        \"name\": \"Conv Block 2\"\n",
    "    },\n",
    "    'layers': tmp_layers_class_0[(37+2-13):(79+2-13-13)]\n",
    "}\n",
    "bl_obj_2 = {\n",
    "    \"meta\": {\n",
    "        \"name\": \"Conv Block 3\"\n",
    "    },\n",
    "    'layers': tmp_layers_class_0[(79+2-13-13):(141+2-13-13-19)]\n",
    "}\n",
    "bl_obj_3 = {\n",
    "    \"meta\": {\n",
    "        \"name\": \"Conv Block 4\"\n",
    "    },\n",
    "    'layers': tmp_layers_class_0[(141+2-13-13-19):]\n",
    "}\n",
    "\n",
    "idxClass = 0\n",
    "classes[idxClass]['blocks'].append(bl_obj_0)\n",
    "classes[idxClass]['blocks'].append(bl_obj_1)\n",
    "classes[idxClass]['blocks'].append(bl_obj_2)\n",
    "classes[idxClass]['blocks'].append(bl_obj_3)\n",
    "\n",
    "\n",
    "bl_obj_0 = {\n",
    "    \"meta\": {\n",
    "        \"name\": \"Conv Block 1\"\n",
    "    },\n",
    "    'layers': tmp_layers_class_1[0:(37+2-13)]\n",
    "}\n",
    "bl_obj_1 = {\n",
    "    \"meta\": {\n",
    "        \"name\": \"Conv Block 2\"\n",
    "    },\n",
    "    'layers': tmp_layers_class_1[(37+2-13):(79+2-13-13)]\n",
    "}\n",
    "bl_obj_2 = {\n",
    "    \"meta\": {\n",
    "        \"name\": \"Conv Block 3\"\n",
    "    },\n",
    "    'layers': tmp_layers_class_1[(79+2-13-13):(141+2-13-13-19)]\n",
    "}\n",
    "bl_obj_3 = {\n",
    "    \"meta\": {\n",
    "        \"name\": \"Conv Block 4\"\n",
    "    },\n",
    "    'layers': tmp_layers_class_1[(141+2-13-13-19):]\n",
    "}\n",
    "\n",
    "idxClass = 1\n",
    "classes[idxClass]['blocks'].append(bl_obj_0)\n",
    "classes[idxClass]['blocks'].append(bl_obj_1)\n",
    "classes[idxClass]['blocks'].append(bl_obj_2)\n",
    "classes[idxClass]['blocks'].append(bl_obj_3)\n",
    "\n",
    "bl_obj_0 = {\n",
    "    \"meta\": {\n",
    "        \"name\": \"Conv Block 1\"\n",
    "    },\n",
    "    'layers': tmp_layers_class_2[0:(37+2-13)]\n",
    "}\n",
    "bl_obj_1 = {\n",
    "    \"meta\": {\n",
    "        \"name\": \"Conv Block 2\"\n",
    "    },\n",
    "    'layers': tmp_layers_class_2[(37+2-13):(79+2-13-13)]\n",
    "}\n",
    "bl_obj_2 = {\n",
    "    \"meta\": {\n",
    "        \"name\": \"Conv Block 3\"\n",
    "    },\n",
    "    'layers': tmp_layers_class_2[(79+2-13-13):(141+2-13-13-19)]\n",
    "}\n",
    "bl_obj_3 = {\n",
    "    \"meta\": {\n",
    "        \"name\": \"Conv Block 4\"\n",
    "    },\n",
    "    'layers': tmp_layers_class_2[(141+2-13-13-19):]\n",
    "}\n",
    "\n",
    "idxClass = 2\n",
    "classes[idxClass]['blocks'].append(bl_obj_0)\n",
    "classes[idxClass]['blocks'].append(bl_obj_1)\n",
    "classes[idxClass]['blocks'].append(bl_obj_2)\n",
    "classes[idxClass]['blocks'].append(bl_obj_3)\n",
    "\n",
    "bl_obj_0 = {\n",
    "    \"meta\": {\n",
    "        \"name\": \"Conv Block 1\"\n",
    "    },\n",
    "    'layers': tmp_layers_class_3[0:(37+2-13)]\n",
    "}\n",
    "bl_obj_1 = {\n",
    "    \"meta\": {\n",
    "        \"name\": \"Conv Block 2\"\n",
    "    },\n",
    "    'layers': tmp_layers_class_3[(37+2-13):(79+2-13-13)]\n",
    "}\n",
    "bl_obj_2 = {\n",
    "    \"meta\": {\n",
    "        \"name\": \"Conv Block 3\"\n",
    "    },\n",
    "    'layers': tmp_layers_class_3[(79+2-13-13):(141+2-13-13-19)]\n",
    "}\n",
    "bl_obj_3 = {\n",
    "    \"meta\": {\n",
    "        \"name\": \"Conv Block 4\"\n",
    "    },\n",
    "    'layers': tmp_layers_class_3[(141+2-13-13-19):]\n",
    "}\n",
    "\n",
    "idxClass = 3\n",
    "classes[idxClass]['blocks'].append(bl_obj_0)\n",
    "classes[idxClass]['blocks'].append(bl_obj_1)\n",
    "classes[idxClass]['blocks'].append(bl_obj_2)\n",
    "classes[idxClass]['blocks'].append(bl_obj_3)\n",
    "\n",
    "bl_obj_0 = {\n",
    "    \"meta\": {\n",
    "        \"name\": \"Conv Block 1\"\n",
    "    },\n",
    "    'layers': tmp_layers_class_4[0:(37+2-13)]\n",
    "}\n",
    "bl_obj_1 = {\n",
    "    \"meta\": {\n",
    "        \"name\": \"Conv Block 2\"\n",
    "    },\n",
    "    'layers': tmp_layers_class_4[(37+2-13):(79+2-13-13)]\n",
    "}\n",
    "bl_obj_2 = {\n",
    "    \"meta\": {\n",
    "        \"name\": \"Conv Block 3\"\n",
    "    },\n",
    "    'layers': tmp_layers_class_4[(79+2-13-13):(141+2-13-13-19)]\n",
    "}\n",
    "bl_obj_3 = {\n",
    "    \"meta\": {\n",
    "        \"name\": \"Conv Block 4\"\n",
    "    },\n",
    "    'layers': tmp_layers_class_4[(141+2-13-13-19):]\n",
    "}\n",
    "\n",
    "idxClass = 4\n",
    "classes[idxClass]['blocks'].append(bl_obj_0)\n",
    "classes[idxClass]['blocks'].append(bl_obj_1)\n",
    "classes[idxClass]['blocks'].append(bl_obj_2)\n",
    "classes[idxClass]['blocks'].append(bl_obj_3)\n",
    "\n",
    "\n",
    "bl_obj_0 = {\n",
    "    \"meta\": {\n",
    "        \"name\": \"Conv Block 1\"\n",
    "    },\n",
    "    'layers': tmp_layers_class_5[0:(37+2-13)]\n",
    "}\n",
    "bl_obj_1 = {\n",
    "    \"meta\": {\n",
    "        \"name\": \"Conv Block 2\"\n",
    "    },\n",
    "    'layers': tmp_layers_class_5[(37+2-13):(79+2-13-13)]\n",
    "}\n",
    "bl_obj_2 = {\n",
    "    \"meta\": {\n",
    "        \"name\": \"Conv Block 3\"\n",
    "    },\n",
    "    'layers': tmp_layers_class_5[(79+2-13-13):(141+2-13-13-19)]\n",
    "}\n",
    "bl_obj_3 = {\n",
    "    \"meta\": {\n",
    "        \"name\": \"Conv Block 4\"\n",
    "    },\n",
    "    'layers': tmp_layers_class_5[(141+2-13-13-19):]\n",
    "}\n",
    "\n",
    "idxClass = 5\n",
    "classes[idxClass]['blocks'].append(bl_obj_0)\n",
    "classes[idxClass]['blocks'].append(bl_obj_1)\n",
    "classes[idxClass]['blocks'].append(bl_obj_2)\n",
    "classes[idxClass]['blocks'].append(bl_obj_3)\n",
    "\n",
    "bl_obj_0 = {\n",
    "    \"meta\": {\n",
    "        \"name\": \"Conv Block 1\"\n",
    "    },\n",
    "    'layers': tmp_layers_class_6[0:(37+2-13)]\n",
    "}\n",
    "bl_obj_1 = {\n",
    "    \"meta\": {\n",
    "        \"name\": \"Conv Block 2\"\n",
    "    },\n",
    "    'layers': tmp_layers_class_6[(37+2-13):(79+2-13-13)]\n",
    "}\n",
    "bl_obj_2 = {\n",
    "    \"meta\": {\n",
    "        \"name\": \"Conv Block 3\"\n",
    "    },\n",
    "    'layers': tmp_layers_class_6[(79+2-13-13):(141+2-13-13-19)]\n",
    "}\n",
    "bl_obj_3 = {\n",
    "    \"meta\": {\n",
    "        \"name\": \"Conv Block 4\"\n",
    "    },\n",
    "    'layers': tmp_layers_class_6[(141+2-13-13-19):]\n",
    "}\n",
    "\n",
    "idxClass = 6\n",
    "classes[idxClass]['blocks'].append(bl_obj_0)\n",
    "classes[idxClass]['blocks'].append(bl_obj_1)\n",
    "classes[idxClass]['blocks'].append(bl_obj_2)\n",
    "classes[idxClass]['blocks'].append(bl_obj_3)\n",
    "\n",
    "\n",
    "\n",
    "bl_obj_0 = {\n",
    "    \"meta\": {\n",
    "        \"name\": \"Conv Block 1\"\n",
    "    },\n",
    "    'layers': tmp_layers_class_7[0:(37+2-13)]\n",
    "}\n",
    "bl_obj_1 = {\n",
    "    \"meta\": {\n",
    "        \"name\": \"Conv Block 2\"\n",
    "    },\n",
    "    'layers': tmp_layers_class_7[(37+2-13):(79+2-13-13)]\n",
    "}\n",
    "bl_obj_2 = {\n",
    "    \"meta\": {\n",
    "        \"name\": \"Conv Block 3\"\n",
    "    },\n",
    "    'layers': tmp_layers_class_7[(79+2-13-13):(141+2-13-13-19)]\n",
    "}\n",
    "bl_obj_3 = {\n",
    "    \"meta\": {\n",
    "        \"name\": \"Conv Block 4\"\n",
    "    },\n",
    "    'layers': tmp_layers_class_7[(141+2-13-13-19):]\n",
    "}\n",
    "\n",
    "idxClass = 7\n",
    "classes[idxClass]['blocks'].append(bl_obj_0)\n",
    "classes[idxClass]['blocks'].append(bl_obj_1)\n",
    "classes[idxClass]['blocks'].append(bl_obj_2)\n",
    "classes[idxClass]['blocks'].append(bl_obj_3)\n",
    "\n",
    "bl_obj_0 = {\n",
    "    \"meta\": {\n",
    "        \"name\": \"Conv Block 1\"\n",
    "    },\n",
    "    'layers': tmp_layers_class_8[0:(37+2-13)]\n",
    "}\n",
    "bl_obj_1 = {\n",
    "    \"meta\": {\n",
    "        \"name\": \"Conv Block 2\"\n",
    "    },\n",
    "    'layers': tmp_layers_class_8[(37+2-13):(79+2-13-13)]\n",
    "}\n",
    "bl_obj_2 = {\n",
    "    \"meta\": {\n",
    "        \"name\": \"Conv Block 3\"\n",
    "    },\n",
    "    'layers': tmp_layers_class_8[(79+2-13-13):(141+2-13-13-19)]\n",
    "}\n",
    "bl_obj_3 = {\n",
    "    \"meta\": {\n",
    "        \"name\": \"Conv Block 4\"\n",
    "    },\n",
    "    'layers': tmp_layers_class_8[(141+2-13-13-19):]\n",
    "}\n",
    "\n",
    "idxClass = 8\n",
    "classes[idxClass]['blocks'].append(bl_obj_0)\n",
    "classes[idxClass]['blocks'].append(bl_obj_1)\n",
    "classes[idxClass]['blocks'].append(bl_obj_2)\n",
    "classes[idxClass]['blocks'].append(bl_obj_3)\n",
    "\n",
    "\n",
    "bl_obj_0 = {\n",
    "    \"meta\": {\n",
    "        \"name\": \"Conv Block 1\"\n",
    "    },\n",
    "    'layers': tmp_layers_class_9[0:(37+2-13)]\n",
    "}\n",
    "bl_obj_1 = {\n",
    "    \"meta\": {\n",
    "        \"name\": \"Conv Block 2\"\n",
    "    },\n",
    "    'layers': tmp_layers_class_9[(37+2-13):(79+2-13-13)]\n",
    "}\n",
    "bl_obj_2 = {\n",
    "    \"meta\": {\n",
    "        \"name\": \"Conv Block 3\"\n",
    "    },\n",
    "    'layers': tmp_layers_class_9[(79+2-13-13):(141+2-13-13-19)]\n",
    "}\n",
    "bl_obj_3 = {\n",
    "    \"meta\": {\n",
    "        \"name\": \"Conv Block 4\"\n",
    "    },\n",
    "    'layers': tmp_layers_class_9[(141+2-13-13-19):]\n",
    "}\n",
    "\n",
    "idxClass = 9\n",
    "classes[idxClass]['blocks'].append(bl_obj_0)\n",
    "classes[idxClass]['blocks'].append(bl_obj_1)\n",
    "classes[idxClass]['blocks'].append(bl_obj_2)\n",
    "classes[idxClass]['blocks'].append(bl_obj_3)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "import os\n",
    "\n",
    "for f in os.listdir('..\\\\..\\\\data\\\\v2\\\\images'):\n",
    "    os.remove(os.path.join('..\\\\..\\\\data\\\\v2\\\\images', f))\n",
    "\n",
    "for idx, i in enumerate(arr_guid):\n",
    "    x_index = mini_y[idx]\n",
    "    image = Image.fromarray(x_test[x_index])\n",
    "    image.save('..\\\\..\\\\data\\\\v2\\\\images\\\\'+i+'.png')\n",
    "\n",
    "print('done')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "print(os.path.abspath('..\\\\data\\\\v1\\\\images\\\\'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json \n",
    "\n",
    "result = {}\n",
    "result[\"n_layers\"] = str(len(Block_layers))\n",
    "result[\"classes\"] = classes\n",
    "\n",
    "with open('..\\\\..\\\\data\\\\v2\\\\block_resnet50.json', 'w') as outfile:\n",
    "    json.dump(result, outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    \n",
    "# Import PCA from sklearn\n",
    "from sklearn.decomposition import PCA\n",
    "import pandas as pd\n",
    "\n",
    "# Instantiate PCA\n",
    "pca = PCA(n_components=3)\n",
    "X = pca.fit_transform(pred)\n",
    "\n",
    "print(X.shape)\n",
    "X = X[:,:2]  #just keep the two columns for visualization\n",
    "\n",
    "# Create a new dataset from principal components \n",
    "df = pd.DataFrame(data = X, columns = ['PC1', 'PC2'])\n",
    "\n",
    "target = pd.Series(np.array(y_test[0:1000]).flatten(), name='y')\n",
    "\n",
    "result_df = pd.concat([df, target], axis=1)\n",
    "\n",
    "result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Visualize Principal Components with a scatter plot\n",
    "import matplotlib.pyplot as plt \n",
    "\n",
    "fig = plt.figure(figsize = (8,6))\n",
    "ax = fig.add_subplot(1,1,1) \n",
    "ax.set_xlabel('First Principal Component ', fontsize = 15)\n",
    "ax.set_ylabel('Second Principal Component ', fontsize = 15)\n",
    "ax.set_title('Principal Component Analysis (2PCs)', fontsize = 20)\n",
    "\n",
    "targets = np.unique(y_test)\n",
    "#targets = [4,1]\n",
    "colors = [\"#1f77b4\",\"#ff7f0e\",\"#2ca02c\",\"#d62728\",\"#9467bd\",\"#8c564b\",\"#e377c2\",\"#7f7f7f\",\"#bcbd22\",\"#17becf\"]\n",
    "#colors = [\"#1f77b4\",\"#ff7f0e\"]\n",
    "for target, color in zip(targets, colors):\n",
    "    indicesToKeep = result_df.loc[result_df['y'] == target]\n",
    "    ax.scatter(indicesToKeep['PC1'], \n",
    "               indicesToKeep['PC2'], \n",
    "               c = color, \n",
    "               s = 50)\n",
    "ax.legend(targets)\n",
    "ax.grid()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# alternate method\n",
    "from keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPool2D,GlobalAveragePooling2D\n",
    "\n",
    "x = base_model.output\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "model = Model(inputs = base_model.input, outputs = x)\n",
    "\n",
    "#model = keras.Sequential(\n",
    "#    [\n",
    "#       base_model,\n",
    "#        keras.layers.Flatten(),\n",
    "#        keras.layers.Dense(1024, activation=\"relu\"),\n",
    "#        keras.layers.Dense(10, activation=\"softmax\"),\n",
    "#    ]\n",
    "#)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#image = np.expand_dims(x_test[0], axis=0)\n",
    "image = x_test[0:1000]\n",
    "pred = model_cut.predict(image)\n",
    "\n",
    "pred.shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "keras-gpu-kernel",
   "language": "python",
   "name": "keras-gpu-kernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
